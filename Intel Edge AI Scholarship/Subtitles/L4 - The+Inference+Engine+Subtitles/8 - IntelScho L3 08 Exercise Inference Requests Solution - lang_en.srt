1
00:00:00,000 --> 00:00:05,385
Amazing. You now know how to make inference request to the inference engine.

2
00:00:05,385 --> 00:00:08,670
Let's go ahead and walk through my solution for doing so.

3
00:00:08,670 --> 00:00:10,455
Back in our Workspace,

4
00:00:10,455 --> 00:00:15,270
go ahead and drag over our inference file here, and let's take a look.

5
00:00:15,270 --> 00:00:17,775
Here, there's a few more arguments to use.

6
00:00:17,775 --> 00:00:20,850
We're, again, going to have our model XML file

7
00:00:20,850 --> 00:00:23,775
but we'll also have the location of the image input,

8
00:00:23,775 --> 00:00:28,485
and we'll allow the user to decide whether to use asynchronous or synchronous.

9
00:00:28,485 --> 00:00:32,955
This is just for this application to show the differences between the two,

10
00:00:32,955 --> 00:00:36,540
usually you, as the developer, would decide on this.

11
00:00:36,540 --> 00:00:39,550
Now below, before we get into the exact solution,

12
00:00:39,550 --> 00:00:41,900
I just want to show a little bit about this other code.

13
00:00:41,900 --> 00:00:46,715
We'll once again read in our image and we extract the image shape from there.

14
00:00:46,715 --> 00:00:49,460
We're actually going to use our pre-processing function

15
00:00:49,460 --> 00:00:52,355
we used long ago in the pre-trained models lesson.

16
00:00:52,355 --> 00:00:56,360
Now we can actually iterate through the inputs here.

17
00:00:56,360 --> 00:01:02,405
That's something that we're going to use to feed in to our inference request.

18
00:01:02,405 --> 00:01:06,260
Now here, since we had an argument defending these,

19
00:01:06,260 --> 00:01:09,050
that's how I decide in the code to send

20
00:01:09,050 --> 00:01:12,575
it to either the async inference or synchronous inference.

21
00:01:12,575 --> 00:01:15,320
If it's something other than a or s,

22
00:01:15,320 --> 00:01:18,995
we need to end the program because we don't know what the user actually wants.

23
00:01:18,995 --> 00:01:23,075
Let's first look at my implementation for synchronous inference.

24
00:01:23,075 --> 00:01:25,265
This one is pretty straightforward.

25
00:01:25,265 --> 00:01:27,290
With our executable network,

26
00:01:27,290 --> 00:01:29,690
you just need to use the infer function,

27
00:01:29,690 --> 00:01:31,595
and with our input blob,

28
00:01:31,595 --> 00:01:33,365
we feed in the image.

29
00:01:33,365 --> 00:01:36,110
This is actually going to directly return

30
00:01:36,110 --> 00:01:39,815
the result of the inference so we can return that here.

31
00:01:39,815 --> 00:01:43,235
If we look just at asynchronous inference,

32
00:01:43,235 --> 00:01:46,025
we're going to have the same inputs of

33
00:01:46,025 --> 00:01:51,575
our executable network input blob and image but it's going to handle things differently.

34
00:01:51,575 --> 00:01:56,135
As we mentioned, it starts by starting async.

35
00:01:56,135 --> 00:01:58,460
This will have a request ID.

36
00:01:58,460 --> 00:02:01,295
Here, I just gave it a request ID of zero

37
00:02:01,295 --> 00:02:04,235
because even though we're implementing async here,

38
00:02:04,235 --> 00:02:06,260
we're actually only doing one thing.

39
00:02:06,260 --> 00:02:12,995
It's just our image again with our input to the network named as input blob.

40
00:02:12,995 --> 00:02:15,375
If you had multiple request to make,

41
00:02:15,375 --> 00:02:17,750
you could be feeding in different request IDs.

42
00:02:17,750 --> 00:02:21,410
Then you would refer to these outputs by that ID.

43
00:02:21,410 --> 00:02:23,930
Below, I made a while loop.

44
00:02:23,930 --> 00:02:29,940
It's going to check on the status and wait if the status isn't equal to zero.

45
00:02:29,940 --> 00:02:32,825
If it is, I'm going to wait for a second here.

46
00:02:32,825 --> 00:02:36,095
Now, normally, we're not going to have to actually wait that long.

47
00:02:36,095 --> 00:02:38,479
But if you had a truly complex model,

48
00:02:38,479 --> 00:02:41,125
it could actually be taking longer than that.

49
00:02:41,125 --> 00:02:47,280
Once the status return from the wait function is zero, I'll break the while loop.

50
00:02:47,280 --> 00:02:49,105
There is a difference here.

51
00:02:49,105 --> 00:02:53,545
I'm not returning the exact results here which might seem a little weird.

52
00:02:53,545 --> 00:02:57,750
I did that before with the synchronous function but why not with async.

53
00:02:57,750 --> 00:03:01,900
Well, the difference is to get the output we have to go

54
00:03:01,900 --> 00:03:06,190
a little deeper than just returning the output from,

55
00:03:06,190 --> 00:03:09,845
well, I don't actually see a function here that would return the output.

56
00:03:09,845 --> 00:03:12,590
So while down below,

57
00:03:12,590 --> 00:03:17,680
I'm going to feed out to our test function with an output from each of these.

58
00:03:17,680 --> 00:03:20,365
These outputs are not the same thing.

59
00:03:20,365 --> 00:03:23,315
Now as we move later into the lesson,

60
00:03:23,315 --> 00:03:26,330
you'll actually get to handle this output and extract

61
00:03:26,330 --> 00:03:29,495
the inference request from synchronous and asynchronous.

62
00:03:29,495 --> 00:03:31,175
But we're not going to do that here.

63
00:03:31,175 --> 00:03:34,400
You can take a look into the test code if you want to

64
00:03:34,400 --> 00:03:38,680
find how that's being done but we'll soon hit that in the videos.

65
00:03:38,680 --> 00:03:45,270
Before we leave, I'll go ahead and run the test just to show that it's actually working.

66
00:03:48,890 --> 00:03:52,560
Great. We passed for all six test.

67
00:03:52,560 --> 00:03:55,195
In just a few short lines of code,

68
00:03:55,195 --> 00:03:58,355
we're now able to make inference request to the inference engine,

69
00:03:58,355 --> 00:04:01,100
both synchronously and asynchronously.

70
00:04:01,100 --> 00:04:05,880
Next, let's look at how to actually handle those results.

