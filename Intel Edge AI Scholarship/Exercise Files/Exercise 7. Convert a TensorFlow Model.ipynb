{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a TensorFlow Model\n",
    "\n",
    "Make sure to click the button below before you get started to source the correct environment.\n",
    "\n",
    "<button id=\"ulab-button-663e2c8b\" class=\"ulab-btn--primary\"></button>\n",
    "\n",
    "In this exercise, you'll convert a TensorFlow Model from the Object Detection Model Zoo\n",
    "into an Intermediate Representation using the Model Optimizer.\n",
    "\n",
    "As noted in the related [documentation](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html), \n",
    "there is a difference in method when using a frozen graph vs. an unfrozen graph. Since\n",
    "freezing a graph is a TensorFlow-based function and not one specific to OpenVINO itself,\n",
    "in this exercise, you will only need to work with a frozen graph. However, I encourage you to\n",
    "try to freeze and load an unfrozen model on your own as well.\n",
    "\n",
    "For this exercise, first download the SSD MobileNet V2 COCO model from [here](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz). Use the `tar -xvf` \n",
    "command with the downloaded file to unpack it.\n",
    "\n",
    "From there, find the **Convert a TensorFlow\\* Model** header in the documentation, and\n",
    "feed in the downloaded SSD MobileNet V2 COCO model's `.pb` file. \n",
    "\n",
    "If the conversion is successful, the terminal should let you know that it generated an IR model.\n",
    "The locations of the `.xml` and `.bin` files, as well as execution time of the Model Optimizer,\n",
    "will also be output.\n",
    "\n",
    "**Note**: Converting the TF model will take a little over one minute in the workspace.\n",
    "\n",
    "### Hints & Troubleshooting\n",
    "\n",
    "Make sure to pay attention to the note in this section regarding the \n",
    "`--reverse_input_channels` argument. \n",
    "If you are unsure about this argument, you can read more [here](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_Converting_Model_General.html#when_to_reverse_input_channels).\n",
    "\n",
    "There is additional documentation specific to converting models from TensorFlow's Object\n",
    "Detection Zoo [here](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html).\n",
    "You will likely need both the `--tensorflow_use_custom_operations_config` and\n",
    "`--tensorflow_object_detection_api_pipeline_config` arguments fed with their \n",
    "related files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Solution: Convert a TensorFlow Model\n",
    "\n",
    "First, you can start by checking out the additional documentation specific to TensorFlow\n",
    "models from the Model Detection Zoo [here](https://docs.openvinotoolkit.org/latest/_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html).\n",
    "\n",
    "I noticed three additional arguments that were important here:\n",
    "\n",
    "- `--tensorflow_object_detection_api_pipeline_config`\n",
    "- `--tensorflow_use_custom_operations_config`\n",
    "- `--reverse_input_channels`\n",
    "\n",
    "The first of these just needs the `pipeline.config` file that came with the downloaded model.\n",
    "\n",
    "The second of these needs a JSON support file for TensorFlow models. I found that the\n",
    "`ssd_v2_support.json` extension worked with the MobileNet model here.\n",
    "\n",
    "The final of these is due to the TensorFlow models being trained on RGB images, but the\n",
    "Inference Engine otherwise defaulting to BGR.\n",
    "\n",
    "Now, given that I was in the directory with the frozen model file from TensorFlow, here was the \n",
    "full path to convert my model:\n",
    "\n",
    "```\n",
    "python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py --input_model frozen_inference_graph.pb --tensorflow_object_detection_api_pipeline_config pipeline.config --reverse_input_channels --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
