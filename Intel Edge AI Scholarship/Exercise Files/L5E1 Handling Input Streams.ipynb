{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Input Streams\n",
    "\n",
    "Make sure to click the button below before you get started to source the correct environment.\n",
    "\n",
    "<button id=\"ulab-button-5de618db\" class=\"ulab-btn--primary\"></button>\n",
    "\n",
    "It's time to really get in the think of things for running your app at the edge. Being able to\n",
    "appropriately handle an input stream is a big part of having a working AI or computer vision\n",
    "application. \n",
    "\n",
    "In your case, you will be implementing a function that can handle camera, video or webcam\n",
    "data as input. While unfortunately the classroom workspace won't allow for webcam usage,\n",
    "you can also try that portion of your code out on your local machine if you have a webcam\n",
    "available.\n",
    "\n",
    "As such, the tests here will focus on using a camera image or a video file. You will not need to\n",
    "perform any inference on the input frames, but you will need to do a few other image\n",
    "processing techniques to show you have some of the basics of OpenCV down.\n",
    "\n",
    "Your tasks are to:\n",
    "\n",
    "1. Implement a function that can handle camera image, video file or webcam inputs\n",
    "2. Use `cv2.VideoCapture()` and open the capture stream\n",
    "3. Re-size the frame to 100x100\n",
    "4. Add Canny Edge Detection to the frame with min & max values of 100 and 200, respectively\n",
    "5. Save down the image or video output\n",
    "6. Close the stream and any windows at the end of the application\n",
    "\n",
    "You won't be able to test a webcam input in the workspace unfortunately, but you can use\n",
    "the included video and test image to test your implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Handling Input Streams\n",
    "\n",
    "Let's walk through each of the tasks.\n",
    "\n",
    "> Implement a function that can handle camera image, video file or webcam inputs\n",
    "\n",
    "The main thing here is just to check the `input` argument passed to the command line.\n",
    "\n",
    "This will differ by application, but in this implementation, the argument parser makes note\n",
    "that \"CAM\" is an acceptable input meaning to use the webcam. In that case, the `input_stream`\n",
    "should be set to `0`, as `cv2.VideoCapture()` can use the system camera when set to zero.\n",
    "\n",
    "The next is checking whether the input name is a filepath containing an image file type, \n",
    "such as `.jpg` or `.png`. If so, you'll just set the `input_stream` to that path. You should also\n",
    "set the flag here to note it is a single image, so you can save down the image as part of one\n",
    "of the later steps.\n",
    "\n",
    "The last one is for a video file. It's mostly the same as the image, as the `input_stream` is the\n",
    "filepath passed to the `input` argument, but you don't need to use a flag here.\n",
    "\n",
    "A last thing you should consider in your app here is exception handling - does your app just\n",
    "crash if the input is invalid or missing, or does it still log useful information to the user?\n",
    "\n",
    "> Use `cv2.VideoCapture()` and open the capture stream\n",
    "\n",
    "```\n",
    "capture = cv2.VideoCapture(input_stream)\n",
    "capture.open(args.input)\n",
    "\n",
    "while capture.isOpened():\n",
    "    flag, frame = cap.read()\n",
    "    if not flag:\n",
    "        break\n",
    "```\n",
    "\n",
    "It's a bit outside of the instructions, but it's also important to check whether a key gets \n",
    "pressed within the while loop, to make it easier to exit. \n",
    "\n",
    "You can use:\n",
    "```\n",
    "key_pressed = cv2.waitKey(60)\n",
    "```\n",
    "to check for a key press, and then\n",
    "```\n",
    "if key_pressed == 27:\n",
    "    break\n",
    "```\n",
    "to break the loop, if needed. Key 27 is the Escape button.\n",
    "\n",
    "> Re-size the frame to 100x100\n",
    "\n",
    "```\n",
    "image = cv2.resize(frame, (100, 100))\n",
    "```\n",
    "\n",
    "> Add Canny Edge Detection to the frame with min & max values of 100 and 200, respectively\n",
    "\n",
    "Canny Edge detection is useful for detecting edges in an image, and has been a useful\n",
    "computer vision technique for extracting features. This was a step just so you could get a little\n",
    "more practice with OpenCV.\n",
    "\n",
    "```\n",
    "edges = cv2.Canny(image,100,200)\n",
    "```\n",
    "\n",
    "> Display the resulting frame if it's video, or save it if it is an image\n",
    "\n",
    "For video:\n",
    "```\n",
    "cv2.imshow('display', edges)\n",
    "```\n",
    "For a single image:\n",
    "```\n",
    "cv2.imwrite('output.jpg', edges)\n",
    "```\n",
    "\n",
    "> Close the stream and any windows at the end of the application\n",
    "\n",
    "Make sure to close your windows here so you don't get stuck with them on-screen.\n",
    "\n",
    "```\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "I can then test both an image and a video with the following:\n",
    "\n",
    "```bash\n",
    "python app.py -i blue-car.jpg\n",
    "```\n",
    "\n",
    "```bash\n",
    "python app.py -i test_video.mp4\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
